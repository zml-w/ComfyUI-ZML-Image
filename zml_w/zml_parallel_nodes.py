import concurrent.futures
import nodes
import json
import copy
import random
import traceback
import os
import glob
import torch

# ==========================================
# AnyType HACK - å…è®¸è¿æ¥ä»»ä½•ç±»å‹
# ==========================================
class AlwaysEqualProxy(str):
    def __eq__(self, _):
        return True
    def __ne__(self, _):
        return False

any_type = AlwaysEqualProxy("*")

# ==========================================
# å˜é‡å®šä¹‰èŠ‚ç‚¹ 
# ==========================================

class ZML_ParallelVariableBase:
    """å˜é‡èŠ‚ç‚¹åŸºç±»"""
    def merge_bundle(self, prev_bundle, key, data):
        new_bundle = copy.deepcopy(prev_bundle) if prev_bundle else {}
        if key in new_bundle:
            print(f"[ZML] è­¦å‘Š: å˜é‡ '{{ {key} }}' æ­£åœ¨è¢«è¦†ç›–ã€‚")
        new_bundle[key] = data
        return (new_bundle,)

class ZML_ParallelVariableText:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "æ–‡æœ¬åˆ—è¡¨": ("STRING", {"multiline": True, "default": "æç¤ºè¯1\næç¤ºè¯2\næç¤ºè¯3"}),
                "å ä½ç¬¦": ("STRING", {"default": "æç¤ºè¯", "multiline": False}),
            },
            "optional": { "è¾“å…¥å˜é‡åŒ…": ("VAR_BUNDLE",), }
        }
    RETURN_TYPES = ("VAR_BUNDLE",)
    RETURN_NAMES = ("è¾“å‡ºå˜é‡åŒ…",)
    FUNCTION = "define_var"
    CATEGORY = "image/ZML_å›¾åƒ/å­å·¥ä½œæµ"

    def define_var(self, æ–‡æœ¬åˆ—è¡¨, å ä½ç¬¦, è¾“å…¥å˜é‡åŒ…=None):
        base = ZML_ParallelVariableBase()
        lines = [line.strip() for line in æ–‡æœ¬åˆ—è¡¨.split('\n') if line.strip()]
        data = { "type": "list", "values": lines }
        return base.merge_bundle(è¾“å…¥å˜é‡åŒ…, å ä½ç¬¦, data)

class ZML_ParallelVariableInt:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": { "èµ·å§‹å€¼": ("INT", {"default": 0}), "æ­¥é•¿": ("INT", {"default": 1}), "å ä½ç¬¦": ("STRING", {"default": "æ•´æ•°"}), },
            "optional": { "è¾“å…¥å˜é‡åŒ…": ("VAR_BUNDLE",), }
        }
    RETURN_TYPES = ("VAR_BUNDLE",)
    RETURN_NAMES = ("è¾“å‡ºå˜é‡åŒ…",)
    FUNCTION = "define_var"
    CATEGORY = "image/ZML_å›¾åƒ/å­å·¥ä½œæµ"

    def define_var(self, èµ·å§‹å€¼, æ­¥é•¿, å ä½ç¬¦, è¾“å…¥å˜é‡åŒ…=None):
        base = ZML_ParallelVariableBase()
        data = { "type": "math_int", "start": èµ·å§‹å€¼, "step": æ­¥é•¿ }
        return base.merge_bundle(è¾“å…¥å˜é‡åŒ…, å ä½ç¬¦, data)

class ZML_ParallelVariableFloat:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": { "èµ·å§‹å€¼": ("FLOAT", {"default": 0.0}), "æ­¥é•¿": ("FLOAT", {"default": 0.1}), "å ä½ç¬¦": ("STRING", {"default": "æµ®ç‚¹"}), },
            "optional": { "è¾“å…¥å˜é‡åŒ…": ("VAR_BUNDLE",), }
        }
    RETURN_TYPES = ("VAR_BUNDLE",)
    RETURN_NAMES = ("è¾“å‡ºå˜é‡åŒ…",)
    FUNCTION = "define_var"
    CATEGORY = "image/ZML_å›¾åƒ/å­å·¥ä½œæµ"

    def define_var(self, èµ·å§‹å€¼, æ­¥é•¿, å ä½ç¬¦, è¾“å…¥å˜é‡åŒ…=None):
        base = ZML_ParallelVariableBase()
        data = { "type": "math_float", "start": èµ·å§‹å€¼, "step": æ­¥é•¿ }
        return base.merge_bundle(è¾“å…¥å˜é‡åŒ…, å ä½ç¬¦, data)

class ZML_ParallelVariableSeed:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": { "ç§å­": ("INT", {"default": 0}), "æ¨¡å¼": (["å›ºå®š", "é€’å¢", "éšæœº"],), "å ä½ç¬¦": ("STRING", {"default": "éšæœºç§"}), },
            "optional": { "è¾“å…¥å˜é‡åŒ…": ("VAR_BUNDLE",), }
        }
    RETURN_TYPES = ("VAR_BUNDLE",)
    RETURN_NAMES = ("è¾“å‡ºå˜é‡åŒ…",)
    FUNCTION = "define_var"
    CATEGORY = "image/ZML_å›¾åƒ/å­å·¥ä½œæµ"

    def define_var(self, ç§å­, æ¨¡å¼, å ä½ç¬¦, è¾“å…¥å˜é‡åŒ…=None):
        base = ZML_ParallelVariableBase()
        data = { "type": "seed", "start": ç§å­, "mode": æ¨¡å¼ }
        return base.merge_bundle(è¾“å…¥å˜é‡åŒ…, å ä½ç¬¦, data)

class ZML_ParallelVariableImageFolder:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": { "æ–‡ä»¶å¤¹è·¯å¾„": ("STRING", {"default": "C:\\Images"}), "å ä½ç¬¦": ("STRING", {"default": "å›¾åƒ"}), },
            "optional": { "è¾“å…¥å˜é‡åŒ…": ("VAR_BUNDLE",), }
        }
    RETURN_TYPES = ("VAR_BUNDLE",)
    RETURN_NAMES = ("è¾“å‡ºå˜é‡åŒ…",)
    FUNCTION = "define_var"
    CATEGORY = "image/ZML_å›¾åƒ/å­å·¥ä½œæµ"

    def define_var(self, æ–‡ä»¶å¤¹è·¯å¾„, å ä½ç¬¦, è¾“å…¥å˜é‡åŒ…=None):
        base = ZML_ParallelVariableBase()
        if not os.path.exists(æ–‡ä»¶å¤¹è·¯å¾„):
            print(f"[ZML] é”™è¯¯: æ–‡ä»¶å¤¹ä¸å­˜åœ¨ {æ–‡ä»¶å¤¹è·¯å¾„}")
            files = []
        else:
            exts = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.webp']
            files = []
            for ext in exts:
                files.extend(glob.glob(os.path.join(æ–‡ä»¶å¤¹è·¯å¾„, ext)))
                files.extend(glob.glob(os.path.join(æ–‡ä»¶å¤¹è·¯å¾„, ext.upper())))
            files = sorted(list(set(files)))
        data = { "type": "list", "values": files }
        return base.merge_bundle(è¾“å…¥å˜é‡åŒ…, å ä½ç¬¦, data)

# ==========================================
# å¯¼å‡ºé”šç‚¹
# ==========================================

class ZML_SubflowExportImage:
    @classmethod
    def INPUT_TYPES(s): return {"required": {"å›¾åƒ": ("IMAGE",)}}
    RETURN_TYPES = ()
    OUTPUT_NODE = True
    FUNCTION = "export"
    CATEGORY = "image/ZML_å›¾åƒ/å­å·¥ä½œæµ"
    def export(self, å›¾åƒ): return {}

class ZML_SubflowExportAny:
    @classmethod
    def INPUT_TYPES(s): 
        # ä¿®æ”¹ç‚¹ï¼šè¿™é‡Œä½¿ç”¨ any_type ä»£æ›¿åŸæ¥çš„ nodes.MAX_RESOLUTION
        return {"required": {"ä»»æ„æ•°æ®": (any_type, {"forceInput": True})}}
    RETURN_TYPES = ()
    OUTPUT_NODE = True
    FUNCTION = "export"
    CATEGORY = "image/ZML_å›¾åƒ/å­å·¥ä½œæµ"
    def export(self, ä»»æ„æ•°æ®): return {}

# ==========================================
# æ ¸å¿ƒå®¹å™¨èŠ‚ç‚¹
# ==========================================

class ZML_ParallelJsonContainer:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "JSONå·¥ä½œæµ": ("STRING", {"multiline": True, "dynamicPrompts": False, "placeholder": "åœ¨æ­¤ç²˜è´´å·¥ä½œæµAPIï¼Œå¹¶åœ¨éœ€è¦çš„ä½ç½®é‡Œä½¿ç”¨{{}}åŒ…è£¹å˜é‡åï¼Œå¦‚{{æç¤ºè¯}}ã€‚ "}),
                "æ‰§è¡Œæ¬¡æ•°": ("INT", {"default": 1, "min": 1, "max": 1000}),
                "å¹¶è¡Œçº¿ç¨‹æ•°": ("INT", {"default": 1, "min": 1, "max": 32, "tooltip": "åŒæ—¶æ‰§è¡Œçš„çº¿ç¨‹æ•°ï¼Œå¤šçº¿ç¨‹å¯ä»¥æ˜¾è‘—æé«˜æ‰§è¡Œé€Ÿåº¦ï¼Œå­å·¥ä½œæµä¸ºéœ€è¦åŠ è½½æ¨¡å‹æ¥ç”Ÿå›¾çš„è¯ï¼Œé‚£åªèƒ½å•çº¿ç¨‹æ‰§è¡Œã€‚"}),
                "æ¸…ç†ç¼“å­˜é—´éš”": ("INT", {"default": 0, "min": 0, "max": 200, "tooltip": "æ‰§è¡Œå®ŒæŒ‡å®šæ¬¡æ•°åï¼Œæ¸…ç†ä¸€æ¬¡GPUç¼“å­˜ï¼Œä»¥é‡Šæ”¾å†…å­˜ã€‚"}),
                "è¿”å›å›¾åƒ": (["å¼€å¯", "å…³é—­"], {"default": "å¼€å¯", "tooltip": "å¼€å¯æ—¶ï¼Œè¿”å›ç”Ÿæˆçš„å›¾åƒï¼›å…³é—­æ—¶ï¼Œåªè¿”å›å ä½ç¬¦å›¾åƒï¼Œä»¥å‡å°‘å·¥ä½œæµæ‰§è¡Œæ—¶å ç”¨çš„ç¼“å­˜ã€‚"}),
            },
            "optional": {
                "å˜é‡åŒ…": ("VAR_BUNDLE",),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING") 
    RETURN_NAMES = ("å›¾åƒåˆ—è¡¨", "ä»»æ„æ•°æ®åˆ—è¡¨", "æ‰§è¡ŒçŠ¶æ€")
    
    OUTPUT_IS_LIST = (True, True, False)
    
    FUNCTION = "run_container"
    CATEGORY = "image/ZML_å›¾åƒ/å­å·¥ä½œæµ"

    def run_container(self, JSONå·¥ä½œæµ, æ‰§è¡Œæ¬¡æ•°, å¹¶è¡Œçº¿ç¨‹æ•°, æ¸…ç†ç¼“å­˜é—´éš”, è¿”å›å›¾åƒ, å˜é‡åŒ…=None):
        try:
            workflow_template = json.loads(JSONå·¥ä½œæµ)
        except Exception as e:
            err_msg = f"JSON æ ¼å¼ä¸¥é‡é”™è¯¯: {e}"
            return ([], [], err_msg)

        # --- å˜é‡è§£æé€»è¾‘ ---
        def resolve_variable(key, var_config, index):
            v_type = var_config["type"]
            if v_type == "list":
                values = var_config["values"]
                if not values: return f"é”™è¯¯:å˜é‡{key}åˆ—è¡¨ä¸ºç©º"
                return values[index % len(values)]
            elif v_type == "math_int":
                return int(var_config["start"] + index * var_config["step"])
            elif v_type == "math_float":
                return float(var_config["start"] + index * var_config["step"])
            elif v_type == "seed":
                mode = var_config["mode"]
                start = var_config["start"]
                if mode == "å›ºå®š": return start
                elif mode == "é€’å¢": return start + index
                elif mode == "éšæœº": return random.randint(1, 0xffffffffffffffff)
            return ""

        def smart_replace(obj, current_vars):
            if isinstance(obj, dict):
                return {k: smart_replace(v, current_vars) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [smart_replace(elem, current_vars) for elem in obj]
            elif isinstance(obj, str):
                new_str = obj
                replaced = False
                for key, val in current_vars.items():
                    placeholder = f"{{{{{key}}}}}"
                    if placeholder in new_str:
                        new_str = new_str.replace(placeholder, str(val))
                        replaced = True
                if replaced:
                    try:
                        if "." not in new_str and new_str.lstrip('-').isdigit():
                            return int(new_str)
                    except: pass
                    try:
                        return float(new_str)
                    except: pass
                return new_str
            else:
                return obj

        # --- å•ä»»åŠ¡æ‰§è¡Œå¼•æ“ ---
        def execute_single_workflow(index):
            try:
                # 1. å˜é‡å‡†å¤‡
                current_vars_map = {}
                if å˜é‡åŒ…:
                    for k, v_conf in å˜é‡åŒ….items():
                        current_vars_map[k] = resolve_variable(k, v_conf, index)
                
                # 2. å˜é‡æ›¿æ¢
                current_flow = copy.deepcopy(workflow_template)
                current_flow = smart_replace(current_flow, current_vars_map)

                # 3. é€’å½’æ‰§è¡Œ
                result_cache = {} 
                
                # æ¸…ç†GPUç¼“å­˜
                if æ¸…ç†ç¼“å­˜é—´éš” > 0 and (index +1) % æ¸…ç†ç¼“å­˜é—´éš” == 0:
                    torch.cuda.empty_cache()
                    print(f"[ZML] å·²æ¸…ç†GPUç¼“å­˜ï¼Œå½“å‰ä»»åŠ¡ç´¢å¼•: {index+1}")
                    
                def get_node_result(node_id):
                    if node_id in result_cache: return result_cache[node_id]
                    if node_id not in current_flow: raise Exception(f"èŠ‚ç‚¹ ID {node_id} åœ¨ JSON ä¸­æœªæ‰¾åˆ°")

                    node_data = current_flow[node_id]
                    class_type = node_data["class_type"]
                    inputs_config = node_data.get("inputs", {})

                    if class_type not in nodes.NODE_CLASS_MAPPINGS:
                        raise Exception(f"ç³»ç»Ÿä¸­ç¼ºå°‘èŠ‚ç‚¹ç±»: {class_type}")
                    
                    NodeClass = nodes.NODE_CLASS_MAPPINGS[class_type]
                    node_instance = NodeClass()
                    
                    resolved_inputs = {}
                    for k, v in inputs_config.items():
                        if isinstance(v, list) and len(v) == 2 and isinstance(v[0], str): 
                            dep_res = get_node_result(v[0])
                            if isinstance(dep_res, tuple):
                                idx = v[1] if v[1] < len(dep_res) else -1
                                resolved_inputs[k] = dep_res[idx]
                            else:
                                resolved_inputs[k] = dep_res
                        else:
                            resolved_inputs[k] = v

                    func = getattr(node_instance, getattr(node_instance, "FUNCTION"))
                    output = func(**resolved_inputs)
                    result_cache[node_id] = output
                    return output

                # 4. å¯¼å‡ºç»“æœ
                exp_img, exp_any = None, None
                found_export = False

                for nid, ninfo in current_flow.items():
                    if ninfo["class_type"] == "ZML_SubflowExportImage":
                        found_export = True
                        try:
                            link = ninfo["inputs"].get("å›¾åƒ")
                            if isinstance(link, list):
                                res = get_node_result(link[0])
                                exp_img = res[link[1]] if isinstance(res, tuple) else res
                        except Exception as e:
                            raise Exception(f"å¯¼å‡ºå›¾åƒå¤±è´¥: {str(e)}")
                    elif ninfo["class_type"] == "ZML_SubflowExportAny":
                        found_export = True
                        try:
                            link = ninfo["inputs"].get("ä»»æ„æ•°æ®")
                            if isinstance(link, list):
                                res = get_node_result(link[0])
                                exp_any = res[link[1]] if isinstance(res, tuple) else res
                        except Exception as e:
                             raise Exception(f"å¯¼å‡ºæ•°æ®å¤±è´¥: {str(e)}")
                
                if not found_export:
                    return (None, None, "è­¦å‘Š: JSON ä¸­æœªæ‰¾åˆ° ZMLå¯¼å‡ºèŠ‚ç‚¹")

                return (exp_img, exp_any, "æˆåŠŸ")

            except Exception as e:
                return (None, None, str(e))

        # --- å¹¶è¡Œæ‰§è¡Œ ---
        final_images = []
        final_anys = []
        final_statuses_list = [""] * æ‰§è¡Œæ¬¡æ•°
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=å¹¶è¡Œçº¿ç¨‹æ•°) as executor:
            future_to_idx = {executor.submit(execute_single_workflow, i): i for i in range(æ‰§è¡Œæ¬¡æ•°)}
            
            for future in concurrent.futures.as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    img, any_val, status_msg = future.result()
                    
                    if status_msg == "æˆåŠŸ":
                        final_statuses_list[idx] = f"ä»»åŠ¡ {idx+1}: âœ… æˆåŠŸ"
                        if è¿”å›å›¾åƒ == "å¼€å¯":
                            if img is not None: final_images.append(img)
                        else:
                            # ç”Ÿæˆ1*1å ä½ç¬¦å›¾åƒ
                            placeholder_img = torch.zeros((1, 1, 1, 3), dtype=torch.float32)
                            final_images.append(placeholder_img)
                        if any_val is not None: final_anys.append(str(any_val))
                    else:
                        final_statuses_list[idx] = f"ä»»åŠ¡ {idx+1}: âŒ å¤±è´¥ - {status_msg}"

                except Exception as e:
                    final_statuses_list[idx] = f"ä»»åŠ¡ {idx+1}: ğŸ’¥ ç³»ç»Ÿçº§å¼‚å¸¸ - {str(e)}"
                    traceback.print_exc()

        status_string = "\n\n".join(final_statuses_list)

        return (final_images, final_anys, status_string)

# æ³¨å†Œæ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ZML_SubflowExportImage": ZML_SubflowExportImage,
    "ZML_SubflowExportAny": ZML_SubflowExportAny,
    "ZML_ParallelJsonContainer": ZML_ParallelJsonContainer,
    "ZML_ParallelVariableText": ZML_ParallelVariableText,
    "ZML_ParallelVariableInt": ZML_ParallelVariableInt,
    "ZML_ParallelVariableFloat": ZML_ParallelVariableFloat,
    "ZML_ParallelVariableSeed": ZML_ParallelVariableSeed,
    "ZML_ParallelVariableImageFolder": ZML_ParallelVariableImageFolder,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ZML_SubflowExportImage": "ZML_å¯¼å‡ºå›¾åƒ (å­å·¥ä½œæµ)",
    "ZML_SubflowExportAny": "ZML_å¯¼å‡ºä»»æ„æ•°æ® (å­å·¥ä½œæµ)",
    "ZML_ParallelJsonContainer": "ZML_å¤šçº¿ç¨‹å­å·¥ä½œæµ",
    "ZML_ParallelVariableText": "ZML_å˜é‡_æ–‡æœ¬åˆ—è¡¨",
    "ZML_ParallelVariableInt": "ZML_å˜é‡_æ•´æ•°åºåˆ—",
    "ZML_ParallelVariableFloat": "ZML_å˜é‡_æµ®ç‚¹åºåˆ—",
    "ZML_ParallelVariableSeed": "ZML_å˜é‡_éšæœºç§å­",
    "ZML_ParallelVariableImageFolder": "ZML_å˜é‡_å›¾åƒæ–‡ä»¶å¤¹",
}